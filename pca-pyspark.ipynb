{"cells":[{"cell_type":"markdown","source":["## PCA with PySpark"],"metadata":{}},{"cell_type":"code","source":["# Load dataframe\nwind_sd = spark.read.csv(path=\"/FileStore/tables/wind.csv\", header=True, inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["We are going to select only the columns whose names contain 'u100', 'v100', 'u10', 'v10', 'inss', 'iews', the output and 'year' (to perform the train, validation and test split). Note that if a column name contains the substring 'u100' it automatically contains 'u10' so the condition is simpler. \n\nAfter that we will store the final dataframe in cache because, by omission, Spark does not persist dataframes."],"metadata":{}},{"cell_type":"code","source":["# Keep columns which contain 'u100', 'v100', 'u10', 'v10', 'inss', 'iews', the output and 'year'\nmy_list = wind_sd.columns\nselected_columns = [col for col in my_list if ('u10' in col)| ('v10' in col) | ('inss' in col) | ('iews' in col) | ('year'== col) | ('energy' == col)]\nwind_sd = wind_sd.select(*selected_columns).cache()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Once we have the smaller dataset with 200 columns, we divide it into train, validation and test. In addition, we are going to create a dataframe with train and validation all together. If storage space was an issue, we would create only the trainAndVal dataframe and split it right before PCA.\n\nSince 'year' is no longer an usefull attribute, we get rid of it."],"metadata":{}},{"cell_type":"code","source":["# Create train, validation and test datafames\ntrain = wind_sd.filter(wind_sd.year <= 2006).drop('year')\nval = wind_sd.filter((wind_sd.year == 2007) | (wind_sd.year == 2008)).drop('year')\ntest = wind_sd.filter((wind_sd.year == 2009) | (wind_sd.year == 2010)).drop('year')\ntrainAndVal = wind_sd.filter(wind_sd.year <= 2008).drop('year')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Before using our dataframes we need to convert them into 2 columns dataframes: one with the input attributes and the other with the output class."],"metadata":{}},{"cell_type":"code","source":["# Cast to vectors so that PCA can work with our data\nfrom pyspark.ml.feature import VectorAssembler\n\nignore = ['energy']\n\nassembler = VectorAssembler(\n    inputCols=[x for x in train.columns if x not in ignore],\n    outputCol='features')\n\ntrain_vec = assembler.transform(train).select(['energy', 'features'])\nval_vec = assembler.transform(val).select(['energy', 'features'])\ntest_vec = assembler.transform(test).select(['energy', 'features'])\ntrainAndVal_vec = assembler.transform(trainAndVal).select(['energy', 'features'])"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["The goal now is to compare the performance of different maxDepths in a regression tree. We could compute the PCA in every iteration of the loop, but this is not efficient. Then, the data is transformed to a PC space before the *for* loop.\n\nNote that the trainAndVal_pca and test_pca are computed with another pca model, since in this scenario we include information from train and validation in the training!"],"metadata":{}},{"cell_type":"code","source":["# Perform PCA\nfrom pyspark.ml.feature import PCA\n\npca = PCA(k=200, inputCol=\"features\", outputCol = \"pca_features\")\nmdl_pca = pca.fit(train_vec)\ntrain_pca = mdl_pca.transform(train_vec)\nval_pca = mdl_pca.transform(val_vec)\n\nmdl_pca_trainAndVal = pca.fit(trainAndVal_vec)\ntrainAndVal_pca = mdl_pca_trainAndVal.transform(trainAndVal_vec)\ntest_pca = mdl_pca_trainAndVal.transform(test_vec)\n\nmdl_pca.explainedVariance"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Now, we will test different values of maxDepth and check the Mean Absolute Error with the validation partition. The best maxDepth value will be stored and used in a final model."],"metadata":{}},{"cell_type":"code","source":["# Find best maxDepth\nfrom pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nbest_mae = 1000\nfinal_maxDepth = 0\nevaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n  \nfor maxDepth in range(1, 12):\n  print(\"maxDepth: \", maxDepth)\n  dt = DecisionTreeRegressor(featuresCol='pca_features',\n                           labelCol=\"energy\",\n                           maxDepth = maxDepth)\n  mdl = dt.fit(train_pca)\n  pred_sd = mdl.transform(val_pca)\n  mae = evaluator.evaluate(pred_sd)\n  print(\"MAE: \", mae)\n  \n  if mae < best_mae:\n    final_maxDepth = maxDepth\n    best_mae = mae\n    \nprint(\"The selected maxDepth is \", final_maxDepth)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["We observe how 6 is the optimum maxDepth value. With greater values the model seems to overfit and with smaller ones it is too simple to capture the data relationships. \n\nUsing this hyper-parameter value, we will compute a final model with the train and validation data and evaluate it with the test partition."],"metadata":{}},{"cell_type":"code","source":["# Re-train the model and evaluate it with the test set\nfinal_dt = DecisionTreeRegressor(featuresCol='pca_features',\n                           labelCol=\"energy\",\n                           maxDepth = final_maxDepth)\nfinal_mdl = final_dt.fit(trainAndVal_pca)\npredictions = final_mdl.transform(test_pca)\nevaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\nmae = evaluator.evaluate(predictions)\nprint(\"Final MAE for {} of maxDepth: {}\".format(final_maxDepth, mae))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["MAE value has increased a little bit. It seems like, despite having more data for training the model, predicting the energy produced in 2009 and 2010 is more complicated with our historical data.\n\nWe will now tune the hyper-parameter \"number of Principal Components\". We will check how the performance varies on the validation set changing the number of Principal Components. Since Databricks is paying for this, we will perform the loop in increments of 1."],"metadata":{}},{"cell_type":"code","source":["# Find optimum number of Principal Components\nfrom pyspark.ml import Pipeline\n\nbest_mae = 1000\nfinal_k = 0\nevaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n\nfor k in range(1, 200):\n  print(\"Number of PCs: \", k)\n  \n  pca2 = PCA(k=k, inputCol=\"features\", outputCol = \"pca_features\")\n  dt2 = DecisionTreeRegressor(featuresCol=pca2.getOutputCol(),\n                           labelCol=\"energy\",\n                           maxDepth = final_maxDepth)\n  pipe = Pipeline(stages=[pca2, dt2])\n  \n  mdl_pipe = pipe.fit(train_vec)\n  pred_pipe = mdl_pipe.transform(val_vec)\n  mae = evaluator.evaluate(pred_pipe)\n  print(\"MAE: \", mae)\n  \n  if mae < best_mae:\n    final_k = k\n    best_mae = mae\n    \nprint(\"The selected number of PCs is \", final_k)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Originally, there were 200 Principal Components but we knew that just the first one explained 79% of the variance. From component 11 to 200, the percentage of explained variance was almost negligible. Then, we are in a strong position to ensure that, despite having eliminated most of the input attributes, there is still a lot of redundancy that can be eliminated with PCA."],"metadata":{}},{"cell_type":"code","source":["# Re-train the model and evaluate it with the test set\nfinal_pca = PCA(k=final_k, inputCol=\"features\", outputCol = \"pca_features\")\nfinal_dt2 = DecisionTreeRegressor(featuresCol=final_pca.getOutputCol(),\n                         labelCol=\"energy\",\n                         maxDepth = final_maxDepth)\nfinal_pipe = Pipeline(stages=[final_pca, final_dt2])\n\nmdl_final_pipe = final_pipe.fit(trainAndVal_vec)\nfinal_pred_pipe = mdl_final_pipe.transform(test_vec)\n\nevaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\nmae = evaluator.evaluate(final_pred_pipe)\nprint(\"Final MAE for {} of maxDepth and {} PCs: {}\".format(final_maxDepth, final_k,mae))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["The final performance with only 10 PCs is better than with all of them.\n\nHowever, this was not very efficient. As it has been pointed out, if you compute PCA with k=5 and then PCA with k=10, you are computing the first 5 components twice (once for k=5 and again for k=10). We will try to find a way to compute all PCs once and select the components from there. \n\nTo do so, we will use the feature VectorSlicer, which allows to take n elements from each row in a column of a dataframe. The results should be (and they are) exactly the same as in the previous for loop.\n\nRecall that we had all the Princpal Components pre-calculated previously in the dataframes train_pca, val_pca, test_pca and trainAndVal_pca."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorSlicer\n\nbest_mae = 1000\nfinal_k = 0\nevaluator = RegressionEvaluator(labelCol=\"energy\", predictionCol=\"prediction\", metricName=\"mae\")\n\nfor k in range(1, 200):\n  print(\"Number of PCs: \", k)\n  \n  slicer = VectorSlicer(inputCol=\"pca_features\", outputCol=\"subset_pca_features\", indices=range(0,k))\n  \n  slice_train_pca = slicer.transform(train_pca)\n  slice_val_pca = slicer.transform(val_pca)\n  \n  opt_dt = DecisionTreeRegressor(featuresCol='subset_pca_features',\n                           labelCol=\"energy\",\n                           maxDepth = final_maxDepth)\n  \n  opt_mdl = opt_dt.fit(slice_train_pca)\n  opt_predictions = opt_mdl.transform(slice_val_pca)\n  mae = evaluator.evaluate(opt_predictions)\n  print(\"MAE: \", mae)\n  \n  if mae < best_mae:\n    final_k = k\n    best_mae = mae\n    \nprint(\"The selected number of Principal Components is \", final_k)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["As expected, the results are identical as the ones obtained with the least-efficient solution."],"metadata":{}}],"metadata":{"name":"2019-01-21 - DBFS Example","notebookId":1583292842141774},"nbformat":4,"nbformat_minor":0}
